package org.ldk.batteries;

import javax.annotation.Nullable;

import org.ldk.enums.Network;
import org.ldk.structs.*;

import java.io.IOException;
import java.util.HashSet;


/**
 * A simple utility class which assists in constructing a fresh or deserializing from disk a ChannelManager and one or
 * more ChannelMonitors.
 *
 * Also constructs a PeerManager and spawns a background thread to monitor for and notify you of relevant Events.
 *
 * Note that you must ensure you hold a reference to any constructed ChannelManagerConstructor objects to ensure you
 * continue to receive events generated by the background thread which will be stopped if this object is garbage
 * collected.
 */
public class ChannelManagerConstructor {
    /**
     * An Exception that indicates the serialized data is invalid and has been corrupted on disk. You should attempt to
     * restore from a backup if there is one which is known to be current. Otherwise, funds may have been lost.
     */
    public static class InvalidSerializedDataException extends Exception {
        InvalidSerializedDataException(String reason) {
            super(reason);
        }
    }

    /**
     * The ChannelManager either deserialized or newly-constructed.
     */
    public final ChannelManager channel_manager;
    /**
     * The latest block has the channel manager saw. If this is non-null it is a 32-byte block hash.
     * You should sync the blockchain starting with the block that builds on this block.
     */
    public final byte[] channel_manager_latest_block_hash;
    /**
     * A list of ChannelMonitors and the last block they each saw. You should sync the blockchain on each individually
     * starting with the block that builds on the hash given.
     * After doing so (and syncing the blockchain on the channel manager as well), you should call chain_sync_completed()
     * and then continue to normal application operation.
     */
    public final TwoTuple_BlockHashChannelMonitorZ[] channel_monitors;
    /**
     * A PeerManager which is constructed to pass messages and handle connections to peers.
     *
     * This is `null` until `chain_sync_completed` is called.
     */
    public PeerManager peer_manager = null;
    /**
     * A NioPeerHandler which manages a background thread to handle socket events and pass them to the peer_manager.
	 *
	 * This is `null` until `chain_sync_completed` is called.
     */
    public NioPeerHandler nio_peer_handler = null;

    private final ChainMonitor chain_monitor;

    /**
     * The `NetworkGraph` deserialized from the byte given to the constructor when deserializing or the `NetworkGraph`
     * given explicitly to the new-object constructor.
     */
    public final NetworkGraph net_graph;

    /**
     * A mutex holding the `ProbabilisticScorer` which was loaded on startup.
     */
    public final MultiThreadedLockableScore scorer;
    /**
     * We wrap the scorer in a MultiThreadedLockableScore which ultimately gates access to the scorer, however sometimes
     * we want to expose underlying details of the scorer itself. Thus, we expose a safe version that takes the lock
     * then returns a reference to this scorer.
     */
    @Nullable private final ProbabilisticScorer prob_scorer;
    private final Logger logger;
    private final KeysManager keys_manager;

    /**
     * Deserializes a channel manager and a set of channel monitors from the given serialized copies and interface implementations
     *
     * @param filter If provided, the outputs which were previously registered to be monitored for will be loaded into the filter.
     *               Note that if the provided Watch is a ChainWatch and has an associated filter, the previously registered
     *               outputs will be loaded when chain_sync_completed is called.
     */
    public ChannelManagerConstructor(byte[] channel_manager_serialized, byte[][] channel_monitors_serialized, UserConfig config,
                                     KeysManager keys_manager, FeeEstimator fee_estimator, ChainMonitor chain_monitor,
                                     @Nullable Filter filter, byte[] net_graph_serialized,
                                     ProbabilisticScoringParameters scoring_params, byte[] probabilistic_scorer_bytes,
                                     BroadcasterInterface tx_broadcaster, Logger logger) throws InvalidSerializedDataException {
        this.keys_manager = keys_manager;
        EntropySource entropy_source = keys_manager.as_EntropySource();

        Result_NetworkGraphDecodeErrorZ graph_res = NetworkGraph.read(net_graph_serialized, logger);
        if (!graph_res.is_ok()) {
            throw new InvalidSerializedDataException("Serialized Network Graph was corrupt");
        }
        this.net_graph = ((Result_NetworkGraphDecodeErrorZ.Result_NetworkGraphDecodeErrorZ_OK)graph_res).res;
        assert(scoring_params != null);
        assert(probabilistic_scorer_bytes != null);
        Result_ProbabilisticScorerDecodeErrorZ scorer_res = ProbabilisticScorer.read(probabilistic_scorer_bytes, scoring_params, net_graph, logger);
        if (!scorer_res.is_ok()) {
            throw new InvalidSerializedDataException("Serialized ProbabilisticScorer was corrupt");
        }
        this.prob_scorer = ((Result_ProbabilisticScorerDecodeErrorZ.Result_ProbabilisticScorerDecodeErrorZ_OK)scorer_res).res;
        this.scorer = MultiThreadedLockableScore.of(this.prob_scorer.as_Score());
        DefaultRouter router = DefaultRouter.of(this.net_graph, logger, entropy_source.get_secure_random_bytes(), scorer.as_LockableScore());

        final ChannelMonitor[] monitors = new ChannelMonitor[channel_monitors_serialized.length];
        this.channel_monitors = new TwoTuple_BlockHashChannelMonitorZ[monitors.length];
        HashSet<OutPoint> monitor_funding_set = new HashSet();
        for (int i = 0; i < monitors.length; i++) {
            Result_C2Tuple_BlockHashChannelMonitorZDecodeErrorZ res = UtilMethods.C2Tuple_BlockHashChannelMonitorZ_read(channel_monitors_serialized[i], entropy_source, keys_manager.as_SignerProvider());
            if (res instanceof Result_C2Tuple_BlockHashChannelMonitorZDecodeErrorZ.Result_C2Tuple_BlockHashChannelMonitorZDecodeErrorZ_Err) {
                throw new InvalidSerializedDataException("Serialized ChannelMonitor was corrupt");
            }
            byte[] block_hash = ((Result_C2Tuple_BlockHashChannelMonitorZDecodeErrorZ.Result_C2Tuple_BlockHashChannelMonitorZDecodeErrorZ_OK)res).res.get_a();
            monitors[i] = ((Result_C2Tuple_BlockHashChannelMonitorZDecodeErrorZ.Result_C2Tuple_BlockHashChannelMonitorZDecodeErrorZ_OK) res).res.get_b();
            this.channel_monitors[i] = TwoTuple_BlockHashChannelMonitorZ.of(block_hash, monitors[i]);
            if (!monitor_funding_set.add(monitors[i].get_funding_txo().get_a()))
                throw new InvalidSerializedDataException("Set of ChannelMonitors contained duplicates (ie the same funding_txo was set on multiple monitors)");
        }
        Result_C2Tuple_BlockHashChannelManagerZDecodeErrorZ res =
                UtilMethods.C2Tuple_BlockHashChannelManagerZ_read(channel_manager_serialized, keys_manager.as_EntropySource(),
                        keys_manager.as_NodeSigner(), keys_manager.as_SignerProvider(), fee_estimator, chain_monitor.as_Watch(),
                        tx_broadcaster, router.as_Router(), logger, config, monitors);
        if (!res.is_ok()) {
            throw new InvalidSerializedDataException("Serialized ChannelManager was corrupt");
        }
        this.channel_manager = ((Result_C2Tuple_BlockHashChannelManagerZDecodeErrorZ.Result_C2Tuple_BlockHashChannelManagerZDecodeErrorZ_OK)res).res.get_b();
        this.channel_manager_latest_block_hash = ((Result_C2Tuple_BlockHashChannelManagerZDecodeErrorZ.Result_C2Tuple_BlockHashChannelManagerZDecodeErrorZ_OK)res).res.get_a();
        this.chain_monitor = chain_monitor;
        this.logger = logger;
        if (filter != null) {
            for (ChannelMonitor monitor : monitors) {
                monitor.load_outputs_to_watch(filter);
            }
        }
    }

    /**
     * Constructs a channel manager from the given interface implementations
     */
    public ChannelManagerConstructor(Network network, UserConfig config, byte[] current_blockchain_tip_hash, int current_blockchain_tip_height,
                                     KeysManager keys_manager, FeeEstimator fee_estimator, ChainMonitor chain_monitor,
                                     NetworkGraph net_graph, ProbabilisticScoringParameters scoring_params,
                                     BroadcasterInterface tx_broadcaster, Logger logger) {
        this.keys_manager = keys_manager;
        EntropySource entropy_source = keys_manager.as_EntropySource();

        this.net_graph = net_graph;
        assert(scoring_params != null);
        this.prob_scorer = ProbabilisticScorer.of(scoring_params, net_graph, logger);
        this.scorer = MultiThreadedLockableScore.of(this.prob_scorer.as_Score());
        DefaultRouter router = DefaultRouter.of(this.net_graph, logger, entropy_source.get_secure_random_bytes(), scorer.as_LockableScore());

        channel_monitors = new TwoTuple_BlockHashChannelMonitorZ[0];
        channel_manager_latest_block_hash = null;
        this.chain_monitor = chain_monitor;
        BestBlock block = BestBlock.of(current_blockchain_tip_hash, current_blockchain_tip_height);
        ChainParameters params = ChainParameters.of(network, block);
        channel_manager = ChannelManager.of(fee_estimator, chain_monitor.as_Watch(), tx_broadcaster, router.as_Router(), logger,
            keys_manager.as_EntropySource(), keys_manager.as_NodeSigner(), keys_manager.as_SignerProvider(), config, params);
        this.logger = logger;
    }

    /**
     * Abstract interface which should handle Events and persist the ChannelManager. When you call chain_sync_completed
     * a background thread is started which will automatically call these methods for you when events occur.
     */
    public interface EventHandler {
        void handle_event(Event events);
        void persist_manager(byte[] channel_manager_bytes);
        void persist_network_graph(byte[] network_graph);
        void persist_scorer(byte[] scorer_bytes);
    }

    BackgroundProcessor background_processor = null;

    /**
     * Utility which adds all of the deserialized ChannelMonitors to the chain watch so that further updates from the
     * ChannelManager are processed as normal.
     *
     * This also spawns a background thread which will call the appropriate methods on the provided
     * EventHandler as required.
     *
     * @param use_p2p_graph_sync determines if we will sync the network graph from peers over the standard (but
     *                           inefficient) lightning P2P protocol. Note that doing so currently requires trusting
     *                           peers as no DoS mechanism is enforced to ensure we don't accept bogus gossip.
     *                           Alternatively, you may sync the net_graph exposed in this object via Rapid Gossip Sync.
     */
    public void chain_sync_completed(EventHandler event_handler, boolean use_p2p_graph_sync) {
        if (background_processor != null) { return; }
        for (TwoTuple_BlockHashChannelMonitorZ monitor: channel_monitors) {
            this.chain_monitor.as_Watch().watch_channel(monitor.get_b().get_funding_txo().get_a(), monitor.get_b());
        }
        org.ldk.structs.EventHandler ldk_handler = org.ldk.structs.EventHandler.new_impl(event_handler::handle_event);

        final IgnoringMessageHandler ignoring_handler = IgnoringMessageHandler.of();
        P2PGossipSync graph_msg_handler = P2PGossipSync.of(net_graph, Option_UtxoLookupZ.none(), logger);
        this.peer_manager = PeerManager.of(channel_manager.as_ChannelMessageHandler(),
                ignoring_handler.as_RoutingMessageHandler(), ignoring_handler.as_OnionMessageHandler(),
                (int)(System.currentTimeMillis() / 1000), this.keys_manager.as_EntropySource().get_secure_random_bytes(),
                logger, ignoring_handler.as_CustomMessageHandler(), keys_manager.as_NodeSigner());

        try {
            this.nio_peer_handler = new NioPeerHandler(peer_manager);
        } catch (IOException e) {
            throw new IllegalStateException("We should never fail to construct nio objects unless we're on a platform that cannot run LDK.");
        }

        GossipSync gossip_sync;
        if (use_p2p_graph_sync)
            gossip_sync = GossipSync.none();
        else
            gossip_sync = GossipSync.p2_p(graph_msg_handler);

        Option_WriteableScoreZ writeable_score = Option_WriteableScoreZ.some(scorer.as_WriteableScore());

        background_processor = BackgroundProcessor.start(Persister.new_impl(new Persister.PersisterInterface() {
            @Override
            public Result_NoneErrorZ persist_manager(ChannelManager channel_manager) {
                event_handler.persist_manager(channel_manager.write());
                return Result_NoneErrorZ.ok();
            }

            @Override
            public Result_NoneErrorZ persist_graph(NetworkGraph network_graph) {
                event_handler.persist_network_graph(network_graph.write());
                return Result_NoneErrorZ.ok();
            }

            @Override
            public Result_NoneErrorZ persist_scorer(WriteableScore scorer) {
                event_handler.persist_scorer(scorer.write());
                return Result_NoneErrorZ.ok();
            }
        }), ldk_handler, this.chain_monitor, this.channel_manager, gossip_sync, peer_manager, this.logger, writeable_score);
    }

    /**
     * Interrupt the background thread, stopping the background handling of events.
     */
    public void interrupt() {
        if (this.nio_peer_handler != null)
            this.nio_peer_handler.interrupt();
        this.background_processor.stop();
    }
}
